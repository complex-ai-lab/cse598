{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Packages"
      ],
      "metadata": {
        "id": "1NhF8AzWZM63"
      },
      "id": "1NhF8AzWZM63"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vnqGpjMBgxo8",
      "metadata": {
        "id": "vnqGpjMBgxo8"
      },
      "outputs": [],
      "source": [
        "!pip install neuraloperator\n",
        "!pip install deepxde"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**: Since we are using Google Colab make sure to mount your drive and 'cd' into the hw1 folder"
      ],
      "metadata": {
        "id": "Bdx4TMCCZAlJ"
      },
      "id": "Bdx4TMCCZAlJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QcWeFzj0Edwd",
      "metadata": {
        "id": "QcWeFzj0Edwd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gMygMjK1El_N",
      "metadata": {
        "id": "gMygMjK1El_N"
      },
      "outputs": [],
      "source": [
        "cd '/YOUR/hw1/PATH/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f849d467-b2a6-4efa-827b-f93b6a9f6053",
      "metadata": {
        "id": "f849d467-b2a6-4efa-827b-f93b6a9f6053"
      },
      "source": [
        "# Part 1: Fourier Neural Operator (FNO)\n",
        "\n",
        "The following libraries will be necessary for your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9162981-7ee2-427f-8356-35733c066e47",
      "metadata": {
        "id": "d9162981-7ee2-427f-8356-35733c066e47"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Union\n",
        "from neuralop import Trainer\n",
        "from neuralop.data.datasets import load_darcy_flow_small\n",
        "from neuralop.utils import count_model_params\n",
        "from neuralop import LpLoss, H1Loss\n",
        "from fno_block import FourierBlock\n",
        "from spectral_convolution import SpectralConvolution\n",
        "from mlp import MLP\n",
        "\n",
        "# PyTorch random number generator\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yavEA3oOxvqf",
      "metadata": {
        "id": "yavEA3oOxvqf"
      },
      "source": [
        "---\n",
        "\n",
        "## **Learning Objectives**\n",
        "\n",
        "By the end of this assignment, you will be able to:\n",
        "\n",
        "1.  Construct the FNO architecture by implementing its core components: lifting layers and spectral (Fourier) blocks.\n",
        "2.   Understand the inputs and the outputs of the PDE dataset\n",
        "3. Train and evaluate the FNO on Darcy Flow data to assess model performance.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5oNSKxm6Ei8P",
      "metadata": {
        "id": "5oNSKxm6Ei8P"
      },
      "source": [
        "## Fourier Neural Operator Architecture\n",
        "\n",
        "The Fourier Neural Operator maps functions to functions using a sequence of Fourier-based layers. Below is the original diagram from the paper showing the full FNO pipeline.\n",
        "\n",
        "![FNO Architecture](https://zongyi-li.github.io/neural-operator/img/fourier_full_arch5.png)\n",
        "\n",
        "*Figure 1: Architecture of the Fourier Neural Operator (Li et al., 2020).*\n",
        "[Source](https://arxiv.org/abs/2010.08895)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce589a9-c00c-45b3-bb26-0ea13b64dd6e",
      "metadata": {
        "id": "cce589a9-c00c-45b3-bb26-0ea13b64dd6e"
      },
      "source": [
        "### Building the Fourier Neural Operator (FNO)\n",
        "\n",
        "We will implement the Fourier Neural Operator (FNO) class, an advanced neural network model used for solving Partial Differential Equations (PDEs) through deep learning. The FNO utilizes Fourier transformations to learn global representations and can be particularly effective for high-dimensional data.\n",
        "\n",
        "Let's start with the Fourier block which you will implement using the modules `SpectralConvolution` and `MLP`.\n",
        "\n",
        "**Task 1: Implement the forward pass of the FourierBlock**\n",
        "* You are given the constructor and you will have to work on the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a394411b-0a16-43a4-b719-f594f4a9a43b",
      "metadata": {
        "id": "a394411b-0a16-43a4-b719-f594f4a9a43b"
      },
      "outputs": [],
      "source": [
        "class FourierBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Fourier block used in the Fourier Neural Operator (FNO).\n",
        "    Combines spectral convolution, MLP, and convolution layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, modes: Union[List[int], int], in_channels: int, out_channels: int,\n",
        "                 hidden_size: int, activation: nn.Module = nn.GELU()) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize the spectral convolution (Fourier layer)\n",
        "        self.fourier = SpectralConvolution(in_channels, out_channels, modes)\n",
        "\n",
        "        # MLP layer (which will do a linear transformation of the input)\n",
        "        self.mlp = MLP(len(modes), in_channels, out_channels, hidden_size, activation)\n",
        "\n",
        "        # Initialize the 2D convolution layer with kernel size of 3 and padding of 1\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "\n",
        "        # Activation function for the block\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the FourierBlock.\n",
        "\n",
        "        Parameters:\n",
        "        ----------\n",
        "        x: torch.Tensor\n",
        "            Input tensor of shape [batch, channels, *sizes]\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "        x: torch.Tensor\n",
        "            Output tensor of shape [batch, channels, *sizes]\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO - Apply spectral convolution to input tensor\n",
        "        x_ft = ...\n",
        "\n",
        "        # TODO - Apply 2D convolution to input tensor\n",
        "        x_conv = ...\n",
        "\n",
        "        # Add the Fourier and convolution outputs\n",
        "        x = x_ft + x_conv\n",
        "\n",
        "        # TODO - Apply MLP to the result\n",
        "        x_mlp = ...\n",
        "        x = ...\n",
        "\n",
        "        # TODO - Apply activation function to the final result\n",
        "        return ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e143d2a9",
      "metadata": {
        "id": "e143d2a9"
      },
      "source": [
        "**Task 2: Construst the FNO class**\n",
        "*  Below is the skeleton of the `FNO` class. Certain parts are intentionally left blank for you to complete - **marked TODO for code you need to complete**. Follow the comments to understand what each part should accomplish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d46296",
      "metadata": {
        "id": "b3d46296"
      },
      "outputs": [],
      "source": [
        "class FNO(nn.Module):\n",
        "    \"\"\"\n",
        "    Fourier Neural Operator (FNO) for solving PDEs.\n",
        "    \"\"\"\n",
        "    def __init__(self, modes: List[int], num_fourier_layers: int, in_channels: int,\n",
        "                 lifting_channels: int, projection_channels: int, out_channels: int,\n",
        "                 hidden_channels: int, activation: nn.Module):\n",
        "        super().__init__()\n",
        "        self.dim = len(modes)\n",
        "        self.activation = activation\n",
        "\n",
        "        # Lifting layer\n",
        "        self.lifting = MLP(2, in_channels, hidden_channels, lifting_channels)\n",
        "\n",
        "        # TODO - Initialize a list of num_fourier_layers FourierBlock modules\n",
        "        #        with modes, hidden_channels, hidden_size and activation as parameters.\n",
        "        #        You are free to choose which hidden_size is best for the model\n",
        "        self.fourier_blocks = nn.ModuleList([\n",
        "            ...\n",
        "        ])\n",
        "\n",
        "        # TODO - Use projection layers\n",
        "        self.q1 = ...\n",
        "        self.final = ...\n",
        "\n",
        "    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
        "        # TODO - Pass input to lifting layer\n",
        "        x = ...\n",
        "\n",
        "        # TODO - Pass the input through each FourierBlock sequentially\n",
        "        for fourier_block in self.fourier_blocks:\n",
        "            x = ...\n",
        "\n",
        "        # Permute the dimensions back to [batch, sizes, channels].\n",
        "        x = x.permute(0, *range(2, self.dim + 2), 1)\n",
        "\n",
        "        # TODO - Apply projection and final layer\n",
        "        x = ...\n",
        "        x = ...\n",
        "        x = ...\n",
        "\n",
        "        # Permute to [batch, channels, sizes] format for output and return.\n",
        "        return x.permute(0, -1, *range(1, self.dim + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "622c2aa9-35c2-4b93-a03c-c8f56b472c84",
      "metadata": {
        "id": "622c2aa9-35c2-4b93-a03c-c8f56b472c84"
      },
      "source": [
        "## Training the Fourier Neural Operator on Darcy Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HWgjkqr-IU9N",
      "metadata": {
        "id": "HWgjkqr-IU9N"
      },
      "source": [
        "### **Darcy Flow: Problem Statement**\n",
        "\n",
        "We consider the steady-state form of the 2D Darcy Flow equation on the unit square domain. This is a second-order, linear, elliptic PDE given by:\n",
        "\n",
        "$$\n",
        "-\\nabla \\cdot \\left( a(x) \\nabla u(x) \\right) = f(x), \\quad x \\in (0, 1)^2\n",
        "$$\n",
        "\n",
        "with Dirichlet boundary condition:\n",
        "\n",
        "$$\n",
        "u(x) = 0, \\quad x \\in \\partial(0, 1)^2\n",
        "$$\n",
        "\n",
        "Here:\n",
        "- $a(x) \\in L^\\infty((0, 1)^2; \\mathbb{R}_+)$ is the **diffusion coefficient**\n",
        "- $f(x) \\in L^2((0, 1)^2; \\mathbb{R})$ is the **forcing function**\n",
        "- $u(x)$ is the **solution** (e.g., pressure field)\n",
        "\n",
        "---\n",
        "\n",
        "This PDE arises in many physical systems:\n",
        "- Subsurface fluid pressure in porous media\n",
        "- Deformation of elastic materials\n",
        "- Electric potential in conductive materials\n",
        "\n",
        "We aim to learn the **solution operator** that maps the coefficient $a(x)$ to the solution $u(x)$:\n",
        "\n",
        "$$\n",
        "a(x) \\mapsto u(x)\n",
        "$$\n",
        "\n",
        "Even though the PDE is linear, the solution operator is **nonlinear** due to the dependence on the spatially varying coefficient $a(x)$.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xyk4Gn-pljZq",
      "metadata": {
        "id": "Xyk4Gn-pljZq"
      },
      "source": [
        "### **Exploring the Darcy Flow Dataset**\n",
        "\n",
        "You will load the data, visualize it, read the description to the dataset can be found [here](https://zenodo.org/records/12784353), and answer reflection questions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "451222b2-459c-48d1-9a1b-07dedc5cd408",
      "metadata": {
        "id": "451222b2-459c-48d1-9a1b-07dedc5cd408"
      },
      "source": [
        "**Loading the Darcy Flow dataset in 128x128 resolution:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd849f5-28bb-4e55-a42f-405e7e197ecf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecd849f5-28bb-4e55-a42f-405e7e197ecf",
        "outputId": "f020344f-3f6d-44a4-bc67-daf8bf503dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test db for resolution 16 with 100 samples \n",
            "Loading test db for resolution 32 with 50 samples \n"
          ]
        }
      ],
      "source": [
        "# Load Darcy flow dataset\n",
        "from pathlib import Path\n",
        "\n",
        "data_root = Path(\"../data/\")\n",
        "\n",
        "train_loader, test_loaders, data_processor = load_darcy_flow_small(\n",
        "    n_train=1000,\n",
        "    batch_size=32,\n",
        "    data_root=data_root,\n",
        "    test_resolutions=[16, 32],\n",
        "    n_tests=[100, 50],\n",
        "    test_batch_sizes=[32, 32],\n",
        ")\n",
        "data_processor = data_processor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UqzD1mcGGa5P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqzD1mcGGa5P",
        "outputId": "53cc1a6d-3d13-43b5-e5fa-f5414ebceedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function load_darcy_flow_small in module neuralop.data.datasets.darcy:\n",
            "\n",
            "load_darcy_flow_small(n_train, n_tests, batch_size, test_batch_sizes, data_root=PosixPath('/usr/local/lib/python3.11/dist-packages/neuralop/data/datasets/data'), test_resolutions=[16, 32], encode_input=False, encode_output=True, encoding='channel-wise', channel_dim=1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(load_darcy_flow_small)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mp_2Qi84ZJPz",
      "metadata": {
        "id": "mp_2Qi84ZJPz"
      },
      "source": [
        "**Run a quick visualization of the input and ground truth data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00124c89-f2cb-4ff3-8123-6625ce7331b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "00124c89-f2cb-4ff3-8123-6625ce7331b4",
        "outputId": "31d2d357-6578-4ec6-f165-2f8e3dd07a76"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#You can change the resolution from 16 to 32 to see the resolution difference if you'd like.\n",
        "#Note: Because DeepONet trains and tests on same resolution, and our Darcy Flow dataset only contains training\n",
        "# data of resolution 16, testing with 16 here is recommended for a better comparison (in DeepONet section of this HW).\n",
        "test_samples = test_loaders[16].dataset\n",
        "\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "for index in range(3):\n",
        "    data = test_samples[index]\n",
        "    data = data_processor.preprocess(data, batched=False)\n",
        "    # Input x\n",
        "    x = data['x']\n",
        "    # Ground-truth\n",
        "    y = data['y']\n",
        "\n",
        "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
        "    ax.imshow(x[0], cmap='gray')\n",
        "    if index == 0:\n",
        "        ax.set_title('Input x')\n",
        "\n",
        "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
        "    ax.imshow(y.squeeze())\n",
        "    if index == 0:\n",
        "        ax.set_title('Ground-truth y')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8PHgvelha8VK",
      "metadata": {
        "id": "8PHgvelha8VK"
      },
      "source": [
        "**Task 3: Reflection Prompt**\n",
        "\n",
        "- What is the input x and how does it relate to the Darcy Flow equation?\n",
        "- What does the output y represent in this context?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C3myF5qcbOp1",
      "metadata": {
        "id": "C3myF5qcbOp1"
      },
      "source": [
        "<style>\n",
        "  .custom-background {\n",
        "    background-color: #f4eb4eff;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "  }\n",
        "</style>\n",
        "<div class=\"custom-background\">\n",
        "  Write your response here:\n",
        "</div>\n",
        "\n",
        "*  ...\n",
        "\n",
        "* ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f083b5ee-807b-4045-85b9-533eb1845e71",
      "metadata": {
        "id": "f083b5ee-807b-4045-85b9-533eb1845e71"
      },
      "source": [
        "### FNO Model\n",
        "\n",
        "**Task 4: instance of our FNO model**\n",
        "* Let's create an instance of our FNO model and tune the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6910b855-f1cf-4967-8011-792bff9832c7",
      "metadata": {
        "id": "6910b855-f1cf-4967-8011-792bff9832c7"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "# TODO - Tune hyperparameters of FNO;\n",
        "# hint: use small values for channels and no more than 6 layers\n",
        "model = FNO(modes=[16, 16], num_fourier_layers=..., in_channels=1,\n",
        "            lifting_channels=..., hidden_channels=..., projection_channels=...,\n",
        "            out_channels=1, activation=nn.GELU())\n",
        "model = model.to(device)\n",
        "\n",
        "# Count model parameters\n",
        "n_params = count_model_params(model)\n",
        "print(f'\\nModel parameters: {n_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71605fb1-5b58-4942-b132-b0e7a8a7179b",
      "metadata": {
        "id": "71605fb1-5b58-4942-b132-b0e7a8a7179b"
      },
      "source": [
        "Create the optimizer and losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3cfae67-0fef-49bb-8139-4ce20aa17bca",
      "metadata": {
        "id": "c3cfae67-0fef-49bb-8139-4ce20aa17bca"
      },
      "outputs": [],
      "source": [
        "# Losses and optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "l2loss = LpLoss(d=2, p=2)\n",
        "h1loss = H1Loss(d=2)\n",
        "train_loss = h1loss\n",
        "eval_losses = {'h1': h1loss, 'l2': l2loss}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec744f1a-39f5-40dc-b139-d10c035f535a",
      "metadata": {
        "id": "ec744f1a-39f5-40dc-b139-d10c035f535a"
      },
      "source": [
        "Visualize created instances for model and others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9b88c3-481d-4572-a1f2-14cbe8d61577",
      "metadata": {
        "id": "4f9b88c3-481d-4572-a1f2-14cbe8d61577"
      },
      "outputs": [],
      "source": [
        "print('\\n### MODEL ###\\n', model)\n",
        "print('\\n### OPTIMIZER ###\\n', optimizer)\n",
        "print('\\n### SCHEDULER ###\\n', scheduler)\n",
        "print('\\n### LOSSES ###')\n",
        "print(f'\\n * Train: {train_loss}')\n",
        "print(f'\\n * Test: {eval_losses}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "399b39c0-ebab-4e47-a281-26e737acc0f3",
      "metadata": {
        "id": "399b39c0-ebab-4e47-a281-26e737acc0f3"
      },
      "source": [
        "Train the model using the trainer. For 20 epochs, it should take a few minutes only.\n",
        "\n",
        "Aim for your `16_l2` metric (L2 loss in 16x16 resolution images) to be less than 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d11fb7-29f4-4d9c-bf01-fd0b322dbbea",
      "metadata": {
        "id": "d0d11fb7-29f4-4d9c-bf01-fd0b322dbbea"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "# eval_interval=3\n",
        "trainer = Trainer(model=model, n_epochs=20, device=device, data_processor=data_processor,\n",
        "                 use_distributed=False, verbose=True)\n",
        "trainer.train(train_loader=train_loader, test_loaders=test_loaders,\n",
        "              optimizer=optimizer, scheduler=scheduler,\n",
        "              regularizer=False, training_loss=train_loss, eval_losses=eval_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18527467-6f5e-48ce-b711-378daafd025b",
      "metadata": {
        "id": "18527467-6f5e-48ce-b711-378daafd025b"
      },
      "source": [
        "### Plot the prediction, and compare with the ground-truth\n",
        "\n",
        "**Note:**\n",
        "* We trained on images of low resolution for a small number of epochs. In practice, we would train at larger resolution, on many more samples and epochs.\n",
        "* However, for practicality, we created a minimal example that:\n",
        "  - fits in just a few Mb of memory\n",
        "  - can be trained quickly on CPU\n",
        "\n",
        "In practice we would train a Neural Operator on one or multiple GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f509f74f-2a53-43de-8707-a3ccb03dc332",
      "metadata": {
        "id": "f509f74f-2a53-43de-8707-a3ccb03dc332"
      },
      "outputs": [],
      "source": [
        "# Visualization of predictions\n",
        "test_samples = test_loaders[32].dataset\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "for index in range(3):\n",
        "    data = test_samples[index]\n",
        "    data = data_processor.preprocess(data, batched=False)\n",
        "    x = data['x']\n",
        "    y = data['y']\n",
        "    out = model(x.unsqueeze(0))\n",
        "\n",
        "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
        "    ax.imshow(x[0], cmap='gray')\n",
        "    if index == 0:\n",
        "        ax.set_title('Input x')\n",
        "\n",
        "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
        "    ax.imshow(y.squeeze())\n",
        "    if index == 0:\n",
        "        ax.set_title('Ground-truth y')\n",
        "\n",
        "    ax = fig.add_subplot(3, 3, index*3 + 3)\n",
        "    ax.imshow(out.squeeze().detach().numpy())\n",
        "    if index == 0:\n",
        "        ax.set_title('Model prediction')\n",
        "\n",
        "fig.suptitle('Inputs, Ground-truth, and Model Prediction')\n",
        "plt.tight_layout()\n",
        "plt.savefig('neural_ops_output.png', dpi=500, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7106f8d3-1f1e-462d-ad11-e72a96d521e4",
      "metadata": {
        "id": "7106f8d3-1f1e-462d-ad11-e72a96d521e4"
      },
      "source": [
        "# Part 2: DeepONets\n",
        "\n",
        "In this section, you will implement the DeepONet class, another advanced neural network model used for solving Partial Differential Equations (PDEs) through deep learning. The trunk and branch method in DeepONet allows for the separation of input functions and locations, enabling efficient and flexible learning of nonlinear operators by independently processing the function space and input space.\n",
        "\n",
        "Below is the skeleton of the `DeepONet` class. Certain parts are intentionally left blank for you to complete - **marked TODO for code you need to complete**. Follow the comments to understand what each part should accomplish."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v3m2l-iKNO5A",
      "metadata": {
        "id": "v3m2l-iKNO5A"
      },
      "source": [
        "![Deep ONet Architecture](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs42256-021-00302-5/MediaObjects/42256_2021_302_Fig1_HTML.png?as=webp)\n",
        "\n",
        "*Figure 1: Illustrations of the problem set-up and new architectures of DeepONets that lead to good generalization. (Lu et al., 2021).*\n",
        "[Source](https://www.nature.com/articles/s42256-021-00302-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p_yHlv32yyGV",
      "metadata": {
        "id": "p_yHlv32yyGV"
      },
      "source": [
        "---\n",
        "\n",
        "## **Learning Objectives**\n",
        "\n",
        "By the end of this assignment, you will be able to:\n",
        "\n",
        "1.  Construct the DeepONet architecture by implementing its two key components: the branch network (which encodes input functions) and the trunk network (which encodes evaluation coordinates).\n",
        "\n",
        "2. Understand the role of each sub-network in the DeepONet framework, and how their outputs are combined to approximate an operator that maps input functions to solution functions.\n",
        "\n",
        "---\n",
        "\n",
        "<!-- **Goals**\n",
        "\n",
        "1.   Construct Architecture\n",
        "2.   Understanding what goes into each module branch and trunk -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "381559c5",
      "metadata": {
        "id": "381559c5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62e4651d-b08c-4508-9c83-15e9f20bf2f4",
      "metadata": {
        "id": "62e4651d-b08c-4508-9c83-15e9f20bf2f4"
      },
      "source": [
        "### Training with DeepONet in Darcy flow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ce4cd3-9fdc-45a4-813c-495290d54488",
      "metadata": {
        "id": "30ce4cd3-9fdc-45a4-813c-495290d54488"
      },
      "source": [
        "**Loading and extracting the Darcy Flow small dataset:**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DAGjnR-IdQox",
      "metadata": {
        "id": "DAGjnR-IdQox"
      },
      "source": [
        "Data Preparation\n",
        "\n",
        "**Task 5: Create 2D spatial coordinates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FidZyU5SdJ_f",
      "metadata": {
        "id": "FidZyU5SdJ_f"
      },
      "outputs": [],
      "source": [
        "# Load the Darcy flow dataset and reshape the input functions (u) and outputs (y) for DeepONet.\n",
        "\n",
        "# Load Darcy Flow data\n",
        "train_data = torch.load(\"../data/darcy_train_16.pt\")\n",
        "test_data = torch.load(\"../data/darcy_test_16.pt\")\n",
        "\n",
        "x_train = train_data[\"x\"].float()  # shape: (1000, 16, 16)\n",
        "y_train = train_data[\"y\"].float()\n",
        "x_test = test_data[\"x\"].float()\n",
        "y_test = test_data[\"y\"].float()\n",
        "\n",
        "# Flatten function input (u values) for branch net\n",
        "X_branch_train = x_train.reshape(x_train.shape[0], -1)  # (1000, 256)\n",
        "Y_branch_train = y_train.reshape(y_train.shape[0], -1)\n",
        "X_branch_test = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "\n",
        "# Trunk input:\n",
        "# TODO: Create 2D spatial coordinates (shared across all samples)\n",
        "H, W = x_train.shape[1], x_train.shape[2]\n",
        "grid_x, grid_y = ...\n",
        "X_trunk = ...  # (256, 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6FUw7jkYdgBo",
      "metadata": {
        "id": "6FUw7jkYdgBo"
      },
      "source": [
        "Model Definition (Unstacked DeepONet)\n",
        "\n",
        "**Task 6: Implement DeepONet**\n",
        "* Implement a simple dense neural net used for both branch and trunk\n",
        "* Create the unstacked DeepONet class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ZH4Ja-4dLvG",
      "metadata": {
        "id": "9ZH4Ja-4dLvG"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement a simple dense neural net used for both branch and trunk\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, layers, activation=nn.ReLU):\n",
        "        super().__init__()\n",
        "        net = []\n",
        "        # TODO: Build a nn.Sequential MLP using `layers` and the activation function\n",
        "        for ...\n",
        "\n",
        "        self.net = nn.Sequential(*net)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Forward through the built MLP and return the output\n",
        "        return ...\n",
        "\n",
        "\n",
        "# TODO: Create the unstacked DeepONet class using einsum to merge outputs from branch and trunk networks.\n",
        "class DeepONet(nn.Module):\n",
        "    \"\"\"\n",
        "    Unstacked DeepONet: merges branch and trunk outputs via an inner product.\n",
        "\n",
        "    branch_net: maps input function samples u -> R^p      (shape: [B, p])\n",
        "    trunk_net:  maps coords x -> R^p                      (shape: [N, p])\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, branch_layers, trunk_layers):\n",
        "        super().__init__()\n",
        "        # TODO: Instantiate branch and trunk networks with DenseNet\n",
        "        self.branch_net = ...\n",
        "        self.trunk_net = ...\n",
        "\n",
        "    def forward(self, u, coords):\n",
        "        \"\"\"\n",
        "        u:      [B, u_dim]\n",
        "        coords: [N, x_dim]\n",
        "        Returns:\n",
        "            y:  [B, N]\n",
        "        \"\"\"\n",
        "        # TODO: Compute branch and trunk\n",
        "        branch_out = ...\n",
        "        trunk_out = ...\n",
        "         # TODO: Merge with einsum\n",
        "         # Hint: https://stackoverflow.com/questions/26089893/understanding-numpys-einsum\n",
        "        return ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55zYkT7KdtbK",
      "metadata": {
        "id": "55zYkT7KdtbK"
      },
      "outputs": [],
      "source": [
        "class LpLoss(object):\n",
        "    '''\n",
        "    loss function with rel/abs Lp loss\n",
        "    from https://github.com/neuraloperator/physics_informed/blob/master/train_utils/losses.py#L152\n",
        "    '''\n",
        "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
        "        super(LpLoss, self).__init__()\n",
        "\n",
        "        #Dimension and Lp-norm type are postive\n",
        "        assert d > 0 and p > 0\n",
        "\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "        self.reduction = reduction\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def abs(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        #Assume uniform mesh\n",
        "        h = 1.0 / (x.size()[1] - 1.0)\n",
        "\n",
        "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(all_norms)\n",
        "            else:\n",
        "                return torch.sum(all_norms)\n",
        "\n",
        "        return all_norms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 7: Train your DeepONet**\n",
        "* Define and tune hyperparameters\n",
        "* Define your DeeopONet model\n",
        "* Train the DeeopONet model"
      ],
      "metadata": {
        "id": "hpz4IfI6b63o"
      },
      "id": "hpz4IfI6b63o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ha-E7Egkda-a",
      "metadata": {
        "id": "Ha-E7Egkda-a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: Hyperparameters\n",
        "num_epochs = ...\n",
        "learning_rate = ...\n",
        "\n",
        "# Model initialization\n",
        "in_dim = x_train.shape[-1] * x_train.shape[-2]  # 1616 = 256\n",
        "#TODO: Define branch and trunk layers\n",
        "branch_layers = [in_dim, ..., ...]\n",
        "trunk_layers = ...\n",
        "\n",
        "model = DeepONet(branch_layers, trunk_layers).to(device)\n",
        "\n",
        "# Optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = LpLoss(size_average=True)\n",
        "\n",
        "# TODO: Implement the training loop to minimize L2 loss over the predicted and true outputs.\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # TODO: Forward pass\n",
        "    pred = ...\n",
        "\n",
        "    # TODO: Compute loss\n",
        "    loss = ...\n",
        "\n",
        "    # TODO: Backpropagation\n",
        "    ...\n",
        "    ...\n",
        "\n",
        "    # Logging\n",
        "    if epoch % 100 == 0 or epoch == num_epochs - 1:\n",
        "        print(f\"Epoch {epoch}: Train Lp Loss = {loss.item():.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HtgC1_oMMGbq",
      "metadata": {
        "id": "HtgC1_oMMGbq"
      },
      "source": [
        "Plot the prediction and compare with the ground-truth data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IA302SLQgz2v",
      "metadata": {
        "id": "IA302SLQgz2v"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Number of samples to visualize\n",
        "num_samples = 3\n",
        "\n",
        "fig, axes = plt.subplots(num_samples, 3, figsize=(9, 3 * num_samples))\n",
        "titles = ['Input $x$', 'Ground-truth $y$', 'Model prediction']\n",
        "\n",
        "sample_indices = torch.randperm(len(x_test))[:num_samples]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_branch_test.to(device), torch.tensor(X_trunk, dtype=torch.float32, device=device)).cpu()\n",
        "preds_cpu = preds.cpu().detach()\n",
        "\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    input_field = x_test[idx].cpu().squeeze().reshape(16, 16)\n",
        "    true_output = y_test[idx].cpu().squeeze().reshape(16, 16)\n",
        "    pred_output = preds_cpu[idx].squeeze().reshape(16, 16)\n",
        "\n",
        "    for j, (data, cmap) in enumerate(zip(\n",
        "        [input_field, true_output, pred_output],\n",
        "        ['gray', 'viridis', 'viridis']  # grayscale only for input\n",
        "    )):\n",
        "        ax = axes[i, j] if num_samples > 1 else axes[j]\n",
        "        ax.imshow(data, cmap=cmap)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        if i == 0:\n",
        "            ax.set_title(titles[j], fontsize=12)\n",
        "\n",
        "plt.suptitle(\"Inputs, Ground-truth, and Model Prediction\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "cse598",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}